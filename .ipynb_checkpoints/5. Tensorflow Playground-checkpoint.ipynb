{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOpraBbnYkFX"
   },
   "source": [
    "Please make sure your code runs and the graphs and figures are displayed in your notebook before submitting (use %matplotlib inline).\n",
    "\n",
    "Additionally, upload any images you plan to incorporate in your notebook as attachments so we can see them in case the uploaded images don't appear properly on our end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Us35DnGLYkUU"
   },
   "source": [
    "#1: Tensorflow Playground (10 pts)\n",
    "\n",
    "In this question, you will be playing with [Tensorflow Playground](https://playground.tensorflow.org).\n",
    "\n",
    "\n",
    "Select \"Classification\" as the Problem Type. Among the four datasets shown in DATA, please select the top left dataset.\n",
    "\n",
    "Use the following settings as the DEFAULT settings for all subquestions: Learning rate = 0.03, Activation = Tanh, Regularization = None, Ratio of training to test data = 50%, Noise = 0, Batch Size = 30, input as  ùëã1  with  ùëã2 , One hidden layer with 4 neurons.\n",
    "\n",
    "i) Use the DEFAULT setting and run two experiments - one using Tanh as the activation function and one using the Linear activation function. Report the train, test losses for both at the end of 1000 epochs. What qualitative difference do you observe in the decision boundaries obtained? What do you think is the reason for this?\n",
    "\n",
    "We will now study the effect of certain variations in the network structure or training process, keeping all other aspects the same as in the DEFAULT setting specified above, with Tanh as the activation. (2 points)\n",
    "\n",
    "ii) Effect of number of hidden units: Keep other settings the same as in DEFAULT, report the training loss and test loss at the end of 1000 epochs using 2 neurons and 8 neurons in the hidden layer. What do you observe in terms of the decision boundary obtained as the number of neurons increases? What do you think is the reason for this? (2 points)\n",
    "\n",
    "iii) Effect of Learning rate and number of epochs: Keep other settings the same as in DEFAULT. For learning rate 10, 1, 0.1, 0.01 and 0.0001, report the train, test losses at the end of 100 epochs, 500 epochs and 1000 epochs respectively. What do you observe from the change of loss vs learning rate, and the change of loss vs epoch numbers? Also report your observations on the training and test loss curve (observe if you see noise for certain learning rates and reason why this is happening). (2 points)\n",
    "\n",
    "iv) Effect of the number of layers: Change your activation to ReLU and use a single hidden layer with 4 neurons and then add another hidden layer with 3 neurons and train both your models for 1000 epochs. Comments on your final models and decision boundaries and observe your training and test loss curves as well. (2 points)\n",
    "\n",
    "v) Use the DEFAULT setting. Play around with any hyperparameters, network architectures or input features (such as  sin(ùëã1),ùëã21  etc.), and report the best train and test loss you obtain (test loss should be no greater than 0.06). Attach the screenshot showing your full network, output and the parameters. Briefly justify your results, and comment on what helps/what doesn't help with lowering the loss, etc. (2 points)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMIZm+BUXUprtsgpc+A7Bwy",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
