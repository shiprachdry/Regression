{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9A-qqItOJh0"
   },
   "source": [
    "Please make sure your code runs and the graphs and figures are displayed in your notebook before submitting (use %matplotlib inline).\n",
    "\n",
    "Additionally, upload any images you plan to incorporate in your notebook as attachments so we can see them in case the uploaded images don't appear properly on our end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAlkFP4dOKM4"
   },
   "source": [
    " Ridge/ Lasso Regression (15 points)\n",
    "\n",
    "Use the following code to import the California housing prices dataset and linear models in python. The dataset is taken from https://www.kaggle.com/camnugent/california-housing-prices/version/1. We have removed the categorical variables and rows with missing variables to make it easier to run the models.\n",
    "\n",
    "The data pertains to the houses found in a given California district and some summary stats about them based on the 1990 census data. Be warned the data aren't cleaned so there are some preprocessing steps required! The columns are as follows, their names are pretty self explanitory:\n",
    "\n",
    "longitude\n",
    "\n",
    "latitude\n",
    "\n",
    "housingmedianage\n",
    "\n",
    "total_rooms\n",
    "\n",
    "total_bedrooms\n",
    "\n",
    "population\n",
    "\n",
    "households\n",
    "\n",
    "median_income\n",
    "\n",
    "medianhousevalue\n",
    "\n",
    "ocean_proximity (this feature has been removed from the csv file since it is a categorical variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXvLy-18OT2N"
   },
   "source": [
    "Now,\n",
    "\n",
    "i) Split the data into a training set (75% of data) and a test set (25% of data), using the train_test_split function with random_state = 50. Then scale the data (not including target) so that each of the independent variables would have zero mean and unit variance. You can use the sklearn.preprocessing.scale function for this. Print the first 5 rows of the training set after scaling. (1 point) \n",
    "\n",
    "ii) Use sklearn.linear_model.Lasso and sklearn.linear_model.Ridge classes to do a 5-fold cross validation using sklearn's KFold. For the sweep of the regularization parameter, we will look at a grid of values ranging from $α = 10^{10}$ to $α = 10^{−6}$.\n",
    "\n",
    "In Python, you can consider this range of values as follows: alpha = 10**numpy.linspace(6,-6,100) so that you can generate 100 uniform values between -6 to 6 as power series.\n",
    "\n",
    "Fit the 2 regression models with scaled data and report the best chosen α based on cross validation as well as the corresponding scoring metric. The cross validation should happen on your training data using MSE as the scoring metric. (5 pts) \n",
    "\n",
    "iii) a) Run ridge and lasso regression for all of the α specified above (on training data), and plot the coefficients learned for each of them - there should be one plot each for lasso and ridge, so a total of two plots; different features' weights of each model should be on the same plot with different colors (2 points).\n",
    "\n",
    "  b) What do you qualitatively observe when the value of the regularization parameter changes? (1 point)\n",
    "\n",
    "iv) a) Similarly, use sklearn.linear_model.ElasticNet to do linear regression with different α values, and plot the coefficients learned for each of them (1 point).\n",
    "\n",
    "  b) Observe the plot, then explain the pros and cons of ridge, lasso and Elastic Net models. (1 point)\n",
    "\n",
    "v) Run the following three regression models with MSE loss on the training data (2 points): \n",
    "\n",
    "a) linear regression without regularization \n",
    "\n",
    "b) linear regression with ridge regularization \n",
    "\n",
    "c) linear regression with lasso regularization \n",
    "\n",
    "For part (b) and (c), use only the best regularization parameters. Report the MSE and R2 on the test data for each of the models.\n",
    "\n",
    "vi) Train the 3 models and report metrics with the original data without scaling (1 point)\n",
    "\n",
    "vii) Why did we have to scale the data in ridge and lasso regression? (1 point)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHVgUXbJ3XlB"
   },
   "source": [
    "Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "R1kQqIaQOqBf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I068117\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\I068117\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n",
      "C:\\Users\\I068117\\AppData\\Local\\Temp\\ipykernel_25240\\4002504239.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"housing_data.csv\")\n",
    "X = df.drop(['median_house_value'],axis=1)\n",
    "Y = df['median_house_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UvyTeSvV3amw"
   },
   "outputs": [],
   "source": [
    "df.columns # Show you all the columns in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHh6JcaD3gDt"
   },
   "outputs": [],
   "source": [
    "df.head() # Show you the first 5 rows in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFNaNj8Y3hQF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
